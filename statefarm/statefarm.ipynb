{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Enter State Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "from keras import backend as K\n",
    "from os import environ\n",
    "\n",
    "# user defined function to change keras backend\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "       environ['KERAS_BACKEND'] = backend\n",
    "       reload(K)\n",
    "       assert K.backend() == backend\n",
    "\n",
    "# call the function with \"theano\"\n",
    "set_keras_backend(\"theano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "path = \"data/\"\n",
    "#path = \"data/state/sample/\"\n",
    "from imp import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/train\n"
     ]
    }
   ],
   "source": [
    "#Validation batches\n",
    "%cd /home/ubuntu/data/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in glob('c?'):\n",
    "    os.mkdir('../valid/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dil = pd.read_csv('/home/ubuntu/data/driver_imgs_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p072' 'p051' 'p047' 'p041' 'p021']\n",
      "['c3', 'c9', 'c2', 'c6', 'c5', 'c7', 'c0', 'c4', 'c8', 'c1']\n"
     ]
    }
   ],
   "source": [
    "# get all different drivers from file and select 5 randomely\n",
    "# group by subject\n",
    "allClasses=glob('c?')\n",
    "allDrivers = dil['subject'].drop_duplicates().as_matrix()\n",
    "randValidationDrivers = np.random.choice(allDrivers, 5)\n",
    "print(randValidationDrivers)\n",
    "print(allClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalt pic moved: 3943\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile, move\n",
    "totalPicMoved=0\n",
    "\n",
    "for driveClass in allClasses:\n",
    "    perClassSeries = dil['classname'].isin([driveClass])\n",
    "    picPerClass = dil[perClassSeries]\n",
    "\n",
    "    for driver in randValidationDrivers:\n",
    "        perDriverPic =  picPerClass['subject'].isin([driver])\n",
    "        picPerDriverInClass = picPerClass[perDriverPic]\n",
    "        picArray = picPerDriverInClass['img'].as_matrix()\n",
    "        #select 20% random photos and move it\n",
    "        #numOfValidPic = int(len(picArray)*0.2)\n",
    "        \n",
    "        #print 'num of valid pic ' + str(numOfValidPic) + '/' + str(len(picArray))\n",
    "        #print ('num of valid pic '+str(numOfValidPic)+ '/'+ str(len(picArray)))\n",
    "        \n",
    "        #validationPicArr=np.random.choice(picArray,numOfValidPic)\n",
    "        \n",
    "        shuf = np.random.permutation(picArray)\n",
    "        for pic in  shuf: move(driveClass +'/'+ pic, '../valid/'+ driveClass +'/'+pic)\n",
    "            \n",
    "        totalPicMoved += len(shuf)\n",
    "        \n",
    "print ('totalt pic moved: '+ str(totalPicMoved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18481 images belonging to 10 classes.\n",
      "Found 3943 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18481 images belonging to 10 classes.\n",
      "Found 3943 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rather than using batches, we could just import all the data into an array to save some processing time. (In most examples I'm using the batches, however - just because that's how I happened to start out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18946 images belonging to 10 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-b0afbfb481fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/jhoward/fast-image/nbs/utils.pyc\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mrandom_transform\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_row_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_col_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mtransform_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_matrix_offset_center\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channel_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(x, transform_matrix, channel_index, fill_mode, cval)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarpAffine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn = get_data(path+'train')\n",
    "val = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/val.dat', val)\n",
    "save_array(path+'results/trn.dat', trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val = load_array(path+'results/val.dat')\n",
    "trn = load_array(path+'results/trn.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run sample experiments on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should find that everything that worked on the sample (see statefarm-sample.ipynb), works on the full dataset too. Only better! Because now we have more data. So let's see how they go - the models in this section are exact copies of the sample notebook models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Single conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18946/18946 [==============================] - 114s - loss: 0.2273 - acc: 0.9405 - val_loss: 2.4946 - val_acc: 0.2826\n",
      "Epoch 2/2\n",
      "18946/18946 [==============================] - 114s - loss: 0.0120 - acc: 0.9990 - val_loss: 1.5872 - val_acc: 0.5253\n",
      "Epoch 1/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.0093 - acc: 0.9992 - val_loss: 1.4836 - val_acc: 0.5825\n",
      "Epoch 2/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.0032 - acc: 1.0000 - val_loss: 1.3142 - val_acc: 0.6162\n",
      "Epoch 3/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.0035 - acc: 0.9996 - val_loss: 1.5061 - val_acc: 0.5771\n",
      "Epoch 4/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.0036 - acc: 0.9997 - val_loss: 1.4528 - val_acc: 0.5808\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interestingly, with no regularization or augmentation we're getting some reasonable results from our simple convolutional model. So with augmentation, we hopefully will see some very good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18946 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18946/18946 [==============================] - 114s - loss: 1.2804 - acc: 0.5891 - val_loss: 2.0614 - val_acc: 0.3407\n",
      "Epoch 2/2\n",
      "18946/18946 [==============================] - 114s - loss: 0.6716 - acc: 0.7916 - val_loss: 1.3377 - val_acc: 0.6208\n",
      "Epoch 1/4\n",
      "18946/18946 [==============================] - 115s - loss: 0.4787 - acc: 0.8594 - val_loss: 1.2230 - val_acc: 0.6228\n",
      "Epoch 2/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.3724 - acc: 0.8931 - val_loss: 1.3030 - val_acc: 0.6282\n",
      "Epoch 3/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.3086 - acc: 0.9162 - val_loss: 1.1986 - val_acc: 0.7119\n",
      "Epoch 4/4\n",
      "18946/18946 [==============================] - 114s - loss: 0.2612 - acc: 0.9283 - val_loss: 1.4794 - val_acc: 0.5799\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.2391 - acc: 0.9361 - val_loss: 1.2511 - val_acc: 0.6886\n",
      "Epoch 2/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.2075 - acc: 0.9430 - val_loss: 1.1327 - val_acc: 0.7294\n",
      "Epoch 3/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1800 - acc: 0.9529 - val_loss: 1.1099 - val_acc: 0.7294\n",
      "Epoch 4/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1675 - acc: 0.9557 - val_loss: 1.0660 - val_acc: 0.7363\n",
      "Epoch 5/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1432 - acc: 0.9625 - val_loss: 1.1585 - val_acc: 0.7073\n",
      "Epoch 6/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1358 - acc: 0.9627 - val_loss: 1.1389 - val_acc: 0.6947\n",
      "Epoch 7/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1283 - acc: 0.9665 - val_loss: 1.1329 - val_acc: 0.7369\n",
      "Epoch 8/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1180 - acc: 0.9686 - val_loss: 1.1817 - val_acc: 0.7194\n",
      "Epoch 9/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1137 - acc: 0.9704 - val_loss: 1.0923 - val_acc: 0.7142\n",
      "Epoch 10/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1076 - acc: 0.9720 - val_loss: 1.0983 - val_acc: 0.7358\n",
      "Epoch 11/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.1032 - acc: 0.9736 - val_loss: 1.0206 - val_acc: 0.7458\n",
      "Epoch 12/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.0956 - acc: 0.9740 - val_loss: 0.9039 - val_acc: 0.7809\n",
      "Epoch 13/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.0962 - acc: 0.9740 - val_loss: 1.3386 - val_acc: 0.6587\n",
      "Epoch 14/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.0892 - acc: 0.9777 - val_loss: 1.1150 - val_acc: 0.7470\n",
      "Epoch 15/15\n",
      "18946/18946 [==============================] - 114s - loss: 0.0886 - acc: 0.9773 - val_loss: 1.9190 - val_acc: 0.5802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b6b66f610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=15, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I'm shocked by *how* good these results are! We're regularly seeing 75-80% accuracy on the validation set, which puts us into the top third or better of the competition. With such a simple model and no dropout or semi-supervised learning, this really speaks to the power of this approach to data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Four conv/pooling pairs + dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfortunately, the results are still very unstable - the validation accuracy jumps from epoch to epoch. Perhaps a deeper model with some dropout would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18946 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18946/18946 [==============================] - 159s - loss: 2.6578 - acc: 0.2492 - val_loss: 1.8681 - val_acc: 0.3844\n",
      "Epoch 2/2\n",
      "18946/18946 [==============================] - 158s - loss: 1.8098 - acc: 0.4334 - val_loss: 1.3152 - val_acc: 0.5670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f227f103ad0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18946/18946 [==============================] - 159s - loss: 1.4232 - acc: 0.5405 - val_loss: 1.0877 - val_acc: 0.6452\n",
      "Epoch 2/10\n",
      "18946/18946 [==============================] - 159s - loss: 1.1155 - acc: 0.6346 - val_loss: 1.2730 - val_acc: 0.6878\n",
      "Epoch 3/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.9043 - acc: 0.7025 - val_loss: 1.1393 - val_acc: 0.6354\n",
      "Epoch 4/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.7444 - acc: 0.7529 - val_loss: 1.1037 - val_acc: 0.7087\n",
      "Epoch 5/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.6299 - acc: 0.7955 - val_loss: 0.9123 - val_acc: 0.7455\n",
      "Epoch 6/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.5220 - acc: 0.8275 - val_loss: 1.0418 - val_acc: 0.7484\n",
      "Epoch 7/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.4686 - acc: 0.8495 - val_loss: 1.2907 - val_acc: 0.6599\n",
      "Epoch 8/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.4190 - acc: 0.8653 - val_loss: 1.1321 - val_acc: 0.6906\n",
      "Epoch 9/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.3735 - acc: 0.8802 - val_loss: 1.1235 - val_acc: 0.7458\n",
      "Epoch 10/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.3226 - acc: 0.8969 - val_loss: 1.2040 - val_acc: 0.7343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f227f104d10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.3183 - acc: 0.8976 - val_loss: 1.0359 - val_acc: 0.7688\n",
      "Epoch 2/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.2788 - acc: 0.9109 - val_loss: 1.5806 - val_acc: 0.6705\n",
      "Epoch 3/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.2810 - acc: 0.9124 - val_loss: 0.9836 - val_acc: 0.7887\n",
      "Epoch 4/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.2403 - acc: 0.9244 - val_loss: 1.1832 - val_acc: 0.7493\n",
      "Epoch 5/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.2195 - acc: 0.9303 - val_loss: 1.1524 - val_acc: 0.7510\n",
      "Epoch 6/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.2085 - acc: 0.9359 - val_loss: 1.2245 - val_acc: 0.7415\n",
      "Epoch 7/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.1961 - acc: 0.9399 - val_loss: 1.1232 - val_acc: 0.7654\n",
      "Epoch 8/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.1851 - acc: 0.9416 - val_loss: 1.0956 - val_acc: 0.6892\n",
      "Epoch 9/10\n",
      "18946/18946 [==============================] - 158s - loss: 0.1798 - acc: 0.9451 - val_loss: 1.0586 - val_acc: 0.7740\n",
      "Epoch 10/10\n",
      "18946/18946 [==============================] - 159s - loss: 0.1669 - acc: 0.9471 - val_loss: 1.4633 - val_acc: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f227f104ed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is looking quite a bit better - the accuracy is similar, but the stability is higher. There's still some way to go however..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenet conv features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have so little data, and it is similar to imagenet images (full color photos), using pre-trained VGG weights is likely to be helpful - in fact it seems likely that we won't need to fine-tune the convolutional layer weights much, if at all. So we can pre-compute the output of the last convolutional layer, as we did in lesson 3 when we experimented with dropout. (However this means that we can't use full data augmentation, since we can't pre-compute something that changes every image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# batches shuffle must be set to False when pre-computing features\n",
    "batches = get_batches(path+'train', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18481 images belonging to 10 classes.\n",
      "Found 3943 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batch, test_batch.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "#conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#path = \"/home/ubuntu/data/\"\n",
    "test_batch =  get_batches('/home/ubuntu/data/hope/', batch_size=batch_size, shuffle=False,  target_size=(224,224), class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c2114501d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_test_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#save_array(path+'results/conv_test_feat.dat', conv_test_feat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_model' is not defined"
     ]
    }
   ],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batch, test_batch.nb_sample)\n",
    "\n",
    "#save_array(path+'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'extract_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e4cda6c41ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_test_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/ubuntu/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:14817)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._create_carray (bcolz/carray_ext.c:16431)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._mkdirs (bcolz/carray_ext.c:18353)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m _use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n",
      "\u001b[0;32m/usr/lib/python3.5/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'extract_features'"
     ]
    }
   ],
   "source": [
    "c=bcolz.carray(conv_test_feat, rootdir='/home/ubuntu/', mode='w'); c.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/results/conv_test_feat.dat/meta/sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b92f17606701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_test_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ubuntu/results/conv_test_feat.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/utils.py\u001b[0m in \u001b[0;36mload_array\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bcolz/toplevel.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(rootdir, mode)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:14879)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._read_meta (bcolz/carray_ext.c:19583)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/results/conv_test_feat.dat/meta/sizes'"
     ]
    }
   ],
   "source": [
    "conv_test_feat=load_array('/home/ubuntu/results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/results/conv_test_feat.dat/meta/sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-791451f74926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_test_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ubuntu/results/conv_test_feat.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bcolz/toplevel.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(rootdir, mode)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:14879)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._read_meta (bcolz/carray_ext.c:19583)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/results/conv_test_feat.dat/meta/sizes'"
     ]
    }
   ],
   "source": [
    "conv_test_feat=bcolz.open('/home/ubuntu/results/conv_test_feat.dat')[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_names_arr=test_batch.filenames\n",
    "#save_array(\"test_file_names_arr\", test_file_names_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/img_33247.jpg',\n",
       " 'test/img_5097.jpg',\n",
       " 'test/img_78067.jpg',\n",
       " 'test/img_70914.jpg',\n",
       " 'test/img_55371.jpg',\n",
       " 'test/img_35993.jpg',\n",
       " 'test/img_70738.jpg',\n",
       " 'test/img_31776.jpg',\n",
       " 'test/img_50240.jpg',\n",
       " 'test/img_7687.jpg',\n",
       " 'test/img_47450.jpg',\n",
       " 'test/img_61964.jpg',\n",
       " 'test/img_9305.jpg',\n",
       " 'test/img_77884.jpg',\n",
       " 'test/img_29715.jpg',\n",
       " 'test/img_27640.jpg',\n",
       " 'test/img_94589.jpg',\n",
       " 'test/img_83110.jpg',\n",
       " 'test/img_7475.jpg',\n",
       " 'test/img_59526.jpg',\n",
       " 'test/img_28203.jpg',\n",
       " 'test/img_62588.jpg',\n",
       " 'test/img_82589.jpg',\n",
       " 'test/img_88855.jpg',\n",
       " 'test/img_94038.jpg',\n",
       " 'test/img_65123.jpg',\n",
       " 'test/img_76795.jpg',\n",
       " 'test/img_73611.jpg',\n",
       " 'test/img_63168.jpg',\n",
       " 'test/img_96666.jpg',\n",
       " 'test/img_41729.jpg',\n",
       " 'test/img_85813.jpg',\n",
       " 'test/img_39032.jpg',\n",
       " 'test/img_93046.jpg',\n",
       " 'test/img_79047.jpg',\n",
       " 'test/img_9412.jpg',\n",
       " 'test/img_4339.jpg',\n",
       " 'test/img_70850.jpg',\n",
       " 'test/img_36359.jpg',\n",
       " 'test/img_89628.jpg',\n",
       " 'test/img_65230.jpg',\n",
       " 'test/img_86807.jpg',\n",
       " 'test/img_80100.jpg',\n",
       " 'test/img_33040.jpg',\n",
       " 'test/img_31922.jpg',\n",
       " 'test/img_101934.jpg',\n",
       " 'test/img_3896.jpg',\n",
       " 'test/img_55421.jpg',\n",
       " 'test/img_48545.jpg',\n",
       " 'test/img_71826.jpg',\n",
       " 'test/img_52341.jpg',\n",
       " 'test/img_10756.jpg',\n",
       " 'test/img_76090.jpg',\n",
       " 'test/img_3903.jpg',\n",
       " 'test/img_40512.jpg',\n",
       " 'test/img_98591.jpg',\n",
       " 'test/img_40477.jpg',\n",
       " 'test/img_33612.jpg',\n",
       " 'test/img_19195.jpg',\n",
       " 'test/img_43915.jpg',\n",
       " 'test/img_11885.jpg',\n",
       " 'test/img_97309.jpg',\n",
       " 'test/img_72503.jpg',\n",
       " 'test/img_84577.jpg',\n",
       " 'test/img_20241.jpg',\n",
       " 'test/img_84762.jpg',\n",
       " 'test/img_48452.jpg',\n",
       " 'test/img_71914.jpg',\n",
       " 'test/img_34636.jpg',\n",
       " 'test/img_63399.jpg',\n",
       " 'test/img_40916.jpg',\n",
       " 'test/img_63185.jpg',\n",
       " 'test/img_11107.jpg',\n",
       " 'test/img_33501.jpg',\n",
       " 'test/img_77126.jpg',\n",
       " 'test/img_82989.jpg',\n",
       " 'test/img_56277.jpg',\n",
       " 'test/img_4754.jpg',\n",
       " 'test/img_39594.jpg',\n",
       " 'test/img_47592.jpg',\n",
       " 'test/img_15683.jpg',\n",
       " 'test/img_15041.jpg',\n",
       " 'test/img_46889.jpg',\n",
       " 'test/img_99078.jpg',\n",
       " 'test/img_6883.jpg',\n",
       " 'test/img_23955.jpg',\n",
       " 'test/img_1721.jpg',\n",
       " 'test/img_48262.jpg',\n",
       " 'test/img_43753.jpg',\n",
       " 'test/img_36415.jpg',\n",
       " 'test/img_61481.jpg',\n",
       " 'test/img_35690.jpg',\n",
       " 'test/img_94714.jpg',\n",
       " 'test/img_39420.jpg',\n",
       " 'test/img_67988.jpg',\n",
       " 'test/img_15838.jpg',\n",
       " 'test/img_11367.jpg',\n",
       " 'test/img_81885.jpg',\n",
       " 'test/img_52860.jpg',\n",
       " 'test/img_71910.jpg',\n",
       " 'test/img_22485.jpg',\n",
       " 'test/img_44641.jpg',\n",
       " 'test/img_83266.jpg',\n",
       " 'test/img_38578.jpg',\n",
       " 'test/img_71849.jpg',\n",
       " 'test/img_77548.jpg',\n",
       " 'test/img_38014.jpg',\n",
       " 'test/img_30776.jpg',\n",
       " 'test/img_68965.jpg',\n",
       " 'test/img_90654.jpg',\n",
       " 'test/img_62861.jpg',\n",
       " 'test/img_68711.jpg',\n",
       " 'test/img_32071.jpg',\n",
       " 'test/img_70427.jpg',\n",
       " 'test/img_60917.jpg',\n",
       " 'test/img_71220.jpg',\n",
       " 'test/img_16589.jpg',\n",
       " 'test/img_17281.jpg',\n",
       " 'test/img_83118.jpg',\n",
       " 'test/img_67661.jpg',\n",
       " 'test/img_41745.jpg',\n",
       " 'test/img_100769.jpg',\n",
       " 'test/img_13735.jpg',\n",
       " 'test/img_100752.jpg',\n",
       " 'test/img_90076.jpg',\n",
       " 'test/img_24324.jpg',\n",
       " 'test/img_34363.jpg',\n",
       " 'test/img_40149.jpg',\n",
       " 'test/img_85666.jpg',\n",
       " 'test/img_54225.jpg',\n",
       " 'test/img_72003.jpg',\n",
       " 'test/img_8582.jpg',\n",
       " 'test/img_69152.jpg',\n",
       " 'test/img_95637.jpg',\n",
       " 'test/img_96459.jpg',\n",
       " 'test/img_94960.jpg',\n",
       " 'test/img_29288.jpg',\n",
       " 'test/img_70607.jpg',\n",
       " 'test/img_1637.jpg',\n",
       " 'test/img_47304.jpg',\n",
       " 'test/img_82532.jpg',\n",
       " 'test/img_28643.jpg',\n",
       " 'test/img_97137.jpg',\n",
       " 'test/img_9926.jpg',\n",
       " 'test/img_62938.jpg',\n",
       " 'test/img_81589.jpg',\n",
       " 'test/img_21898.jpg',\n",
       " 'test/img_52853.jpg',\n",
       " 'test/img_64284.jpg',\n",
       " 'test/img_96268.jpg',\n",
       " 'test/img_49602.jpg',\n",
       " 'test/img_30846.jpg',\n",
       " 'test/img_53835.jpg',\n",
       " 'test/img_84643.jpg',\n",
       " 'test/img_95992.jpg',\n",
       " 'test/img_90060.jpg',\n",
       " 'test/img_100308.jpg',\n",
       " 'test/img_27920.jpg',\n",
       " 'test/img_2912.jpg',\n",
       " 'test/img_14656.jpg',\n",
       " 'test/img_95435.jpg',\n",
       " 'test/img_85048.jpg',\n",
       " 'test/img_1549.jpg',\n",
       " 'test/img_81563.jpg',\n",
       " 'test/img_81975.jpg',\n",
       " 'test/img_1279.jpg',\n",
       " 'test/img_24450.jpg',\n",
       " 'test/img_32264.jpg',\n",
       " 'test/img_17762.jpg',\n",
       " 'test/img_64084.jpg',\n",
       " 'test/img_83750.jpg',\n",
       " 'test/img_92703.jpg',\n",
       " 'test/img_26615.jpg',\n",
       " 'test/img_91771.jpg',\n",
       " 'test/img_43754.jpg',\n",
       " 'test/img_13295.jpg',\n",
       " 'test/img_57794.jpg',\n",
       " 'test/img_82882.jpg',\n",
       " 'test/img_78635.jpg',\n",
       " 'test/img_94037.jpg',\n",
       " 'test/img_46736.jpg',\n",
       " 'test/img_25114.jpg',\n",
       " 'test/img_73111.jpg',\n",
       " 'test/img_54190.jpg',\n",
       " 'test/img_60275.jpg',\n",
       " 'test/img_22840.jpg',\n",
       " 'test/img_97639.jpg',\n",
       " 'test/img_98033.jpg',\n",
       " 'test/img_26042.jpg',\n",
       " 'test/img_94104.jpg',\n",
       " 'test/img_76362.jpg',\n",
       " 'test/img_16525.jpg',\n",
       " 'test/img_25868.jpg',\n",
       " 'test/img_50596.jpg',\n",
       " 'test/img_14276.jpg',\n",
       " 'test/img_15488.jpg',\n",
       " 'test/img_10730.jpg',\n",
       " 'test/img_34424.jpg',\n",
       " 'test/img_80750.jpg',\n",
       " 'test/img_3426.jpg',\n",
       " 'test/img_66885.jpg',\n",
       " 'test/img_60113.jpg',\n",
       " 'test/img_1041.jpg',\n",
       " 'test/img_70785.jpg',\n",
       " 'test/img_33921.jpg',\n",
       " 'test/img_99023.jpg',\n",
       " 'test/img_78480.jpg',\n",
       " 'test/img_99296.jpg',\n",
       " 'test/img_39495.jpg',\n",
       " 'test/img_71711.jpg',\n",
       " 'test/img_100386.jpg',\n",
       " 'test/img_99305.jpg',\n",
       " 'test/img_13557.jpg',\n",
       " 'test/img_7332.jpg',\n",
       " 'test/img_48273.jpg',\n",
       " 'test/img_62229.jpg',\n",
       " 'test/img_82442.jpg',\n",
       " 'test/img_40500.jpg',\n",
       " 'test/img_39006.jpg',\n",
       " 'test/img_96477.jpg',\n",
       " 'test/img_28568.jpg',\n",
       " 'test/img_9294.jpg',\n",
       " 'test/img_5615.jpg',\n",
       " 'test/img_62481.jpg',\n",
       " 'test/img_12488.jpg',\n",
       " 'test/img_76873.jpg',\n",
       " 'test/img_4547.jpg',\n",
       " 'test/img_83733.jpg',\n",
       " 'test/img_39588.jpg',\n",
       " 'test/img_4948.jpg',\n",
       " 'test/img_5375.jpg',\n",
       " 'test/img_37767.jpg',\n",
       " 'test/img_74747.jpg',\n",
       " 'test/img_27931.jpg',\n",
       " 'test/img_89169.jpg',\n",
       " 'test/img_95752.jpg',\n",
       " 'test/img_50907.jpg',\n",
       " 'test/img_21368.jpg',\n",
       " 'test/img_16085.jpg',\n",
       " 'test/img_13155.jpg',\n",
       " 'test/img_48163.jpg',\n",
       " 'test/img_63966.jpg',\n",
       " 'test/img_13666.jpg',\n",
       " 'test/img_62812.jpg',\n",
       " 'test/img_52297.jpg',\n",
       " 'test/img_67173.jpg',\n",
       " 'test/img_59591.jpg',\n",
       " 'test/img_62040.jpg',\n",
       " 'test/img_63751.jpg',\n",
       " 'test/img_54665.jpg',\n",
       " 'test/img_12094.jpg',\n",
       " 'test/img_69918.jpg',\n",
       " 'test/img_24101.jpg',\n",
       " 'test/img_17236.jpg',\n",
       " 'test/img_57720.jpg',\n",
       " 'test/img_69405.jpg',\n",
       " 'test/img_39269.jpg',\n",
       " 'test/img_38424.jpg',\n",
       " 'test/img_73059.jpg',\n",
       " 'test/img_15248.jpg',\n",
       " 'test/img_88214.jpg',\n",
       " 'test/img_54785.jpg',\n",
       " 'test/img_75986.jpg',\n",
       " 'test/img_60397.jpg',\n",
       " 'test/img_80159.jpg',\n",
       " 'test/img_82375.jpg',\n",
       " 'test/img_29571.jpg',\n",
       " 'test/img_39921.jpg',\n",
       " 'test/img_55388.jpg',\n",
       " 'test/img_49799.jpg',\n",
       " 'test/img_26838.jpg',\n",
       " 'test/img_25273.jpg',\n",
       " 'test/img_35862.jpg',\n",
       " 'test/img_87126.jpg',\n",
       " 'test/img_38122.jpg',\n",
       " 'test/img_163.jpg',\n",
       " 'test/img_21807.jpg',\n",
       " 'test/img_56213.jpg',\n",
       " 'test/img_83315.jpg',\n",
       " 'test/img_65402.jpg',\n",
       " 'test/img_87099.jpg',\n",
       " 'test/img_83524.jpg',\n",
       " 'test/img_40709.jpg',\n",
       " 'test/img_7952.jpg',\n",
       " 'test/img_67948.jpg',\n",
       " 'test/img_16310.jpg',\n",
       " 'test/img_6742.jpg',\n",
       " 'test/img_52379.jpg',\n",
       " 'test/img_38063.jpg',\n",
       " 'test/img_11530.jpg',\n",
       " 'test/img_94280.jpg',\n",
       " 'test/img_27136.jpg',\n",
       " 'test/img_93135.jpg',\n",
       " 'test/img_36626.jpg',\n",
       " 'test/img_40219.jpg',\n",
       " 'test/img_95602.jpg',\n",
       " 'test/img_70648.jpg',\n",
       " 'test/img_49598.jpg',\n",
       " 'test/img_29981.jpg',\n",
       " 'test/img_17243.jpg',\n",
       " 'test/img_94184.jpg',\n",
       " 'test/img_97448.jpg',\n",
       " 'test/img_15276.jpg',\n",
       " 'test/img_62377.jpg',\n",
       " 'test/img_5119.jpg',\n",
       " 'test/img_88246.jpg',\n",
       " 'test/img_49798.jpg',\n",
       " 'test/img_65168.jpg',\n",
       " 'test/img_71291.jpg',\n",
       " 'test/img_5777.jpg',\n",
       " 'test/img_35907.jpg',\n",
       " 'test/img_88127.jpg',\n",
       " 'test/img_90201.jpg',\n",
       " 'test/img_101601.jpg',\n",
       " 'test/img_52489.jpg',\n",
       " 'test/img_34675.jpg',\n",
       " 'test/img_76729.jpg',\n",
       " 'test/img_42732.jpg',\n",
       " 'test/img_74099.jpg',\n",
       " 'test/img_87991.jpg',\n",
       " 'test/img_101846.jpg',\n",
       " 'test/img_81764.jpg',\n",
       " 'test/img_30448.jpg',\n",
       " 'test/img_49993.jpg',\n",
       " 'test/img_92545.jpg',\n",
       " 'test/img_62754.jpg',\n",
       " 'test/img_45748.jpg',\n",
       " 'test/img_98557.jpg',\n",
       " 'test/img_29479.jpg',\n",
       " 'test/img_2200.jpg',\n",
       " 'test/img_19442.jpg',\n",
       " 'test/img_88772.jpg',\n",
       " 'test/img_44078.jpg',\n",
       " 'test/img_46216.jpg',\n",
       " 'test/img_25146.jpg',\n",
       " 'test/img_79614.jpg',\n",
       " 'test/img_86065.jpg',\n",
       " 'test/img_23432.jpg',\n",
       " 'test/img_95783.jpg',\n",
       " 'test/img_27551.jpg',\n",
       " 'test/img_73620.jpg',\n",
       " 'test/img_7607.jpg',\n",
       " 'test/img_40720.jpg',\n",
       " 'test/img_77851.jpg',\n",
       " 'test/img_50141.jpg',\n",
       " 'test/img_100550.jpg',\n",
       " 'test/img_51633.jpg',\n",
       " 'test/img_28858.jpg',\n",
       " 'test/img_49345.jpg',\n",
       " 'test/img_4194.jpg',\n",
       " 'test/img_19623.jpg',\n",
       " 'test/img_42750.jpg',\n",
       " 'test/img_21974.jpg',\n",
       " 'test/img_23778.jpg',\n",
       " 'test/img_63429.jpg',\n",
       " 'test/img_83767.jpg',\n",
       " 'test/img_66876.jpg',\n",
       " 'test/img_31725.jpg',\n",
       " 'test/img_95293.jpg',\n",
       " 'test/img_88869.jpg',\n",
       " 'test/img_77200.jpg',\n",
       " 'test/img_87716.jpg',\n",
       " 'test/img_64997.jpg',\n",
       " 'test/img_62067.jpg',\n",
       " 'test/img_63883.jpg',\n",
       " 'test/img_13124.jpg',\n",
       " 'test/img_64451.jpg',\n",
       " 'test/img_50000.jpg',\n",
       " 'test/img_99708.jpg',\n",
       " 'test/img_79392.jpg',\n",
       " 'test/img_51498.jpg',\n",
       " 'test/img_3138.jpg',\n",
       " 'test/img_51831.jpg',\n",
       " 'test/img_82765.jpg',\n",
       " 'test/img_8120.jpg',\n",
       " 'test/img_20337.jpg',\n",
       " 'test/img_7226.jpg',\n",
       " 'test/img_56726.jpg',\n",
       " 'test/img_3747.jpg',\n",
       " 'test/img_9800.jpg',\n",
       " 'test/img_101799.jpg',\n",
       " 'test/img_36750.jpg',\n",
       " 'test/img_67169.jpg',\n",
       " 'test/img_47350.jpg',\n",
       " 'test/img_88732.jpg',\n",
       " 'test/img_84690.jpg',\n",
       " 'test/img_33892.jpg',\n",
       " 'test/img_76166.jpg',\n",
       " 'test/img_64295.jpg',\n",
       " 'test/img_22850.jpg',\n",
       " 'test/img_63022.jpg',\n",
       " 'test/img_76884.jpg',\n",
       " 'test/img_54161.jpg',\n",
       " 'test/img_26003.jpg',\n",
       " 'test/img_27932.jpg',\n",
       " 'test/img_12322.jpg',\n",
       " 'test/img_96133.jpg',\n",
       " 'test/img_76967.jpg',\n",
       " 'test/img_6305.jpg',\n",
       " 'test/img_8801.jpg',\n",
       " 'test/img_74446.jpg',\n",
       " 'test/img_89002.jpg',\n",
       " 'test/img_21917.jpg',\n",
       " 'test/img_6252.jpg',\n",
       " 'test/img_38604.jpg',\n",
       " 'test/img_41009.jpg',\n",
       " 'test/img_13283.jpg',\n",
       " 'test/img_12597.jpg',\n",
       " 'test/img_99778.jpg',\n",
       " 'test/img_8606.jpg',\n",
       " 'test/img_59407.jpg',\n",
       " 'test/img_98411.jpg',\n",
       " 'test/img_220.jpg',\n",
       " 'test/img_18877.jpg',\n",
       " 'test/img_23601.jpg',\n",
       " 'test/img_46391.jpg',\n",
       " 'test/img_45680.jpg',\n",
       " 'test/img_64512.jpg',\n",
       " 'test/img_2504.jpg',\n",
       " 'test/img_73118.jpg',\n",
       " 'test/img_78316.jpg',\n",
       " 'test/img_30399.jpg',\n",
       " 'test/img_89724.jpg',\n",
       " 'test/img_90981.jpg',\n",
       " 'test/img_26597.jpg',\n",
       " 'test/img_71941.jpg',\n",
       " 'test/img_41164.jpg',\n",
       " 'test/img_32522.jpg',\n",
       " 'test/img_52066.jpg',\n",
       " 'test/img_40003.jpg',\n",
       " 'test/img_62957.jpg',\n",
       " 'test/img_74021.jpg',\n",
       " 'test/img_94393.jpg',\n",
       " 'test/img_12337.jpg',\n",
       " 'test/img_45456.jpg',\n",
       " 'test/img_2251.jpg',\n",
       " 'test/img_89775.jpg',\n",
       " 'test/img_90293.jpg',\n",
       " 'test/img_96163.jpg',\n",
       " 'test/img_27209.jpg',\n",
       " 'test/img_57445.jpg',\n",
       " 'test/img_15908.jpg',\n",
       " 'test/img_86364.jpg',\n",
       " 'test/img_27956.jpg',\n",
       " 'test/img_99741.jpg',\n",
       " 'test/img_76813.jpg',\n",
       " 'test/img_27557.jpg',\n",
       " 'test/img_20899.jpg',\n",
       " 'test/img_8362.jpg',\n",
       " 'test/img_75560.jpg',\n",
       " 'test/img_41390.jpg',\n",
       " 'test/img_52307.jpg',\n",
       " 'test/img_22311.jpg',\n",
       " 'test/img_23734.jpg',\n",
       " 'test/img_3031.jpg',\n",
       " 'test/img_57236.jpg',\n",
       " 'test/img_6941.jpg',\n",
       " 'test/img_84166.jpg',\n",
       " 'test/img_8664.jpg',\n",
       " 'test/img_24585.jpg',\n",
       " 'test/img_67062.jpg',\n",
       " 'test/img_80865.jpg',\n",
       " 'test/img_34579.jpg',\n",
       " 'test/img_5146.jpg',\n",
       " 'test/img_20704.jpg',\n",
       " 'test/img_83562.jpg',\n",
       " 'test/img_78168.jpg',\n",
       " 'test/img_730.jpg',\n",
       " 'test/img_46679.jpg',\n",
       " 'test/img_30080.jpg',\n",
       " 'test/img_83567.jpg',\n",
       " 'test/img_36297.jpg',\n",
       " 'test/img_60890.jpg',\n",
       " 'test/img_55446.jpg',\n",
       " 'test/img_101138.jpg',\n",
       " 'test/img_36641.jpg',\n",
       " 'test/img_64948.jpg',\n",
       " 'test/img_69249.jpg',\n",
       " 'test/img_85294.jpg',\n",
       " 'test/img_100476.jpg',\n",
       " 'test/img_45236.jpg',\n",
       " 'test/img_15292.jpg',\n",
       " 'test/img_89011.jpg',\n",
       " 'test/img_26717.jpg',\n",
       " 'test/img_72946.jpg',\n",
       " 'test/img_60025.jpg',\n",
       " 'test/img_71146.jpg',\n",
       " 'test/img_3840.jpg',\n",
       " 'test/img_97403.jpg',\n",
       " 'test/img_50165.jpg',\n",
       " 'test/img_74584.jpg',\n",
       " 'test/img_19431.jpg',\n",
       " 'test/img_74177.jpg',\n",
       " 'test/img_67511.jpg',\n",
       " 'test/img_42395.jpg',\n",
       " 'test/img_3659.jpg',\n",
       " 'test/img_48297.jpg',\n",
       " 'test/img_76808.jpg',\n",
       " 'test/img_40623.jpg',\n",
       " 'test/img_7739.jpg',\n",
       " 'test/img_3087.jpg',\n",
       " 'test/img_9506.jpg',\n",
       " 'test/img_97129.jpg',\n",
       " 'test/img_64353.jpg',\n",
       " 'test/img_18377.jpg',\n",
       " 'test/img_2678.jpg',\n",
       " 'test/img_46363.jpg',\n",
       " 'test/img_12080.jpg',\n",
       " 'test/img_65918.jpg',\n",
       " 'test/img_73890.jpg',\n",
       " 'test/img_90084.jpg',\n",
       " 'test/img_35058.jpg',\n",
       " 'test/img_101732.jpg',\n",
       " 'test/img_9223.jpg',\n",
       " 'test/img_13088.jpg',\n",
       " 'test/img_36632.jpg',\n",
       " 'test/img_15181.jpg',\n",
       " 'test/img_62120.jpg',\n",
       " 'test/img_69838.jpg',\n",
       " 'test/img_27467.jpg',\n",
       " 'test/img_28219.jpg',\n",
       " 'test/img_58852.jpg',\n",
       " 'test/img_21491.jpg',\n",
       " 'test/img_85500.jpg',\n",
       " 'test/img_2017.jpg',\n",
       " 'test/img_101848.jpg',\n",
       " 'test/img_9444.jpg',\n",
       " 'test/img_65074.jpg',\n",
       " 'test/img_22894.jpg',\n",
       " 'test/img_10424.jpg',\n",
       " 'test/img_74979.jpg',\n",
       " 'test/img_9283.jpg',\n",
       " 'test/img_99450.jpg',\n",
       " 'test/img_93309.jpg',\n",
       " 'test/img_38289.jpg',\n",
       " 'test/img_42737.jpg',\n",
       " 'test/img_78707.jpg',\n",
       " 'test/img_14711.jpg',\n",
       " 'test/img_31464.jpg',\n",
       " 'test/img_69963.jpg',\n",
       " 'test/img_24274.jpg',\n",
       " 'test/img_30020.jpg',\n",
       " 'test/img_55023.jpg',\n",
       " 'test/img_65829.jpg',\n",
       " 'test/img_78261.jpg',\n",
       " 'test/img_97141.jpg',\n",
       " 'test/img_25709.jpg',\n",
       " 'test/img_68425.jpg',\n",
       " 'test/img_28737.jpg',\n",
       " 'test/img_17129.jpg',\n",
       " 'test/img_31483.jpg',\n",
       " 'test/img_53290.jpg',\n",
       " 'test/img_89890.jpg',\n",
       " 'test/img_47435.jpg',\n",
       " 'test/img_30225.jpg',\n",
       " 'test/img_5527.jpg',\n",
       " 'test/img_40639.jpg',\n",
       " 'test/img_1949.jpg',\n",
       " 'test/img_20303.jpg',\n",
       " 'test/img_59670.jpg',\n",
       " 'test/img_82417.jpg',\n",
       " 'test/img_48368.jpg',\n",
       " 'test/img_85278.jpg',\n",
       " 'test/img_44368.jpg',\n",
       " 'test/img_41835.jpg',\n",
       " 'test/img_9524.jpg',\n",
       " 'test/img_24733.jpg',\n",
       " 'test/img_48939.jpg',\n",
       " 'test/img_58962.jpg',\n",
       " 'test/img_99854.jpg',\n",
       " 'test/img_48407.jpg',\n",
       " 'test/img_39384.jpg',\n",
       " 'test/img_30795.jpg',\n",
       " 'test/img_7364.jpg',\n",
       " 'test/img_60699.jpg',\n",
       " 'test/img_94105.jpg',\n",
       " 'test/img_23313.jpg',\n",
       " 'test/img_15473.jpg',\n",
       " 'test/img_54081.jpg',\n",
       " 'test/img_77224.jpg',\n",
       " 'test/img_81789.jpg',\n",
       " 'test/img_692.jpg',\n",
       " 'test/img_25852.jpg',\n",
       " 'test/img_74293.jpg',\n",
       " 'test/img_94272.jpg',\n",
       " 'test/img_27378.jpg',\n",
       " 'test/img_67650.jpg',\n",
       " 'test/img_50276.jpg',\n",
       " 'test/img_54766.jpg',\n",
       " 'test/img_61704.jpg',\n",
       " 'test/img_52571.jpg',\n",
       " 'test/img_89180.jpg',\n",
       " 'test/img_3770.jpg',\n",
       " 'test/img_82384.jpg',\n",
       " 'test/img_72485.jpg',\n",
       " 'test/img_88972.jpg',\n",
       " 'test/img_22507.jpg',\n",
       " 'test/img_57665.jpg',\n",
       " 'test/img_58814.jpg',\n",
       " 'test/img_25385.jpg',\n",
       " 'test/img_52619.jpg',\n",
       " 'test/img_48776.jpg',\n",
       " 'test/img_54969.jpg',\n",
       " 'test/img_33569.jpg',\n",
       " 'test/img_41850.jpg',\n",
       " 'test/img_84672.jpg',\n",
       " 'test/img_55209.jpg',\n",
       " 'test/img_31835.jpg',\n",
       " 'test/img_11394.jpg',\n",
       " 'test/img_86486.jpg',\n",
       " 'test/img_32611.jpg',\n",
       " 'test/img_62942.jpg',\n",
       " 'test/img_88811.jpg',\n",
       " 'test/img_81664.jpg',\n",
       " 'test/img_83207.jpg',\n",
       " 'test/img_66225.jpg',\n",
       " 'test/img_38678.jpg',\n",
       " 'test/img_28770.jpg',\n",
       " 'test/img_38364.jpg',\n",
       " 'test/img_6710.jpg',\n",
       " 'test/img_48144.jpg',\n",
       " 'test/img_35447.jpg',\n",
       " 'test/img_77785.jpg',\n",
       " 'test/img_89745.jpg',\n",
       " 'test/img_41683.jpg',\n",
       " 'test/img_74604.jpg',\n",
       " 'test/img_77097.jpg',\n",
       " 'test/img_3668.jpg',\n",
       " 'test/img_2243.jpg',\n",
       " 'test/img_79388.jpg',\n",
       " 'test/img_4752.jpg',\n",
       " 'test/img_32771.jpg',\n",
       " 'test/img_82012.jpg',\n",
       " 'test/img_50034.jpg',\n",
       " 'test/img_73650.jpg',\n",
       " 'test/img_93033.jpg',\n",
       " 'test/img_90718.jpg',\n",
       " 'test/img_14955.jpg',\n",
       " 'test/img_42662.jpg',\n",
       " 'test/img_81042.jpg',\n",
       " 'test/img_53714.jpg',\n",
       " 'test/img_50193.jpg',\n",
       " 'test/img_39406.jpg',\n",
       " 'test/img_8906.jpg',\n",
       " 'test/img_40325.jpg',\n",
       " 'test/img_19489.jpg',\n",
       " 'test/img_76780.jpg',\n",
       " 'test/img_89752.jpg',\n",
       " 'test/img_98957.jpg',\n",
       " 'test/img_56827.jpg',\n",
       " 'test/img_33726.jpg',\n",
       " 'test/img_62097.jpg',\n",
       " 'test/img_15627.jpg',\n",
       " 'test/img_9257.jpg',\n",
       " 'test/img_44405.jpg',\n",
       " 'test/img_5528.jpg',\n",
       " 'test/img_15788.jpg',\n",
       " 'test/img_34644.jpg',\n",
       " 'test/img_41881.jpg',\n",
       " 'test/img_40081.jpg',\n",
       " 'test/img_64827.jpg',\n",
       " 'test/img_1744.jpg',\n",
       " 'test/img_59477.jpg',\n",
       " 'test/img_90226.jpg',\n",
       " 'test/img_64539.jpg',\n",
       " 'test/img_56893.jpg',\n",
       " 'test/img_77436.jpg',\n",
       " 'test/img_22975.jpg',\n",
       " 'test/img_25676.jpg',\n",
       " 'test/img_14572.jpg',\n",
       " 'test/img_63006.jpg',\n",
       " 'test/img_75825.jpg',\n",
       " 'test/img_21512.jpg',\n",
       " 'test/img_60160.jpg',\n",
       " 'test/img_100094.jpg',\n",
       " 'test/img_8996.jpg',\n",
       " 'test/img_67753.jpg',\n",
       " 'test/img_75398.jpg',\n",
       " 'test/img_46126.jpg',\n",
       " 'test/img_81753.jpg',\n",
       " 'test/img_84584.jpg',\n",
       " 'test/img_99348.jpg',\n",
       " 'test/img_2070.jpg',\n",
       " 'test/img_88947.jpg',\n",
       " 'test/img_83216.jpg',\n",
       " 'test/img_85340.jpg',\n",
       " 'test/img_26030.jpg',\n",
       " 'test/img_15308.jpg',\n",
       " 'test/img_12433.jpg',\n",
       " 'test/img_102019.jpg',\n",
       " 'test/img_3518.jpg',\n",
       " 'test/img_5628.jpg',\n",
       " 'test/img_85955.jpg',\n",
       " 'test/img_10984.jpg',\n",
       " 'test/img_24195.jpg',\n",
       " 'test/img_29616.jpg',\n",
       " 'test/img_86573.jpg',\n",
       " 'test/img_83492.jpg',\n",
       " 'test/img_35157.jpg',\n",
       " 'test/img_52055.jpg',\n",
       " 'test/img_48427.jpg',\n",
       " 'test/img_44702.jpg',\n",
       " 'test/img_86183.jpg',\n",
       " 'test/img_38056.jpg',\n",
       " 'test/img_61782.jpg',\n",
       " 'test/img_6173.jpg',\n",
       " 'test/img_42147.jpg',\n",
       " 'test/img_5802.jpg',\n",
       " 'test/img_52134.jpg',\n",
       " 'test/img_59677.jpg',\n",
       " 'test/img_56033.jpg',\n",
       " 'test/img_56598.jpg',\n",
       " 'test/img_45893.jpg',\n",
       " 'test/img_77892.jpg',\n",
       " 'test/img_89869.jpg',\n",
       " 'test/img_94485.jpg',\n",
       " 'test/img_97625.jpg',\n",
       " 'test/img_82842.jpg',\n",
       " 'test/img_96548.jpg',\n",
       " 'test/img_48100.jpg',\n",
       " 'test/img_9153.jpg',\n",
       " 'test/img_24287.jpg',\n",
       " 'test/img_75659.jpg',\n",
       " 'test/img_52247.jpg',\n",
       " 'test/img_59555.jpg',\n",
       " 'test/img_58043.jpg',\n",
       " 'test/img_100351.jpg',\n",
       " 'test/img_23892.jpg',\n",
       " 'test/img_84547.jpg',\n",
       " 'test/img_2856.jpg',\n",
       " 'test/img_54979.jpg',\n",
       " 'test/img_92618.jpg',\n",
       " 'test/img_85133.jpg',\n",
       " 'test/img_86415.jpg',\n",
       " 'test/img_18639.jpg',\n",
       " 'test/img_54865.jpg',\n",
       " 'test/img_31192.jpg',\n",
       " 'test/img_15652.jpg',\n",
       " 'test/img_79069.jpg',\n",
       " 'test/img_58160.jpg',\n",
       " 'test/img_64257.jpg',\n",
       " 'test/img_70778.jpg',\n",
       " 'test/img_36936.jpg',\n",
       " 'test/img_12342.jpg',\n",
       " 'test/img_79184.jpg',\n",
       " 'test/img_26760.jpg',\n",
       " 'test/img_27927.jpg',\n",
       " 'test/img_30393.jpg',\n",
       " 'test/img_97375.jpg',\n",
       " 'test/img_46852.jpg',\n",
       " 'test/img_46730.jpg',\n",
       " 'test/img_87837.jpg',\n",
       " 'test/img_92354.jpg',\n",
       " 'test/img_11244.jpg',\n",
       " 'test/img_6995.jpg',\n",
       " 'test/img_14720.jpg',\n",
       " 'test/img_6315.jpg',\n",
       " 'test/img_9087.jpg',\n",
       " 'test/img_39781.jpg',\n",
       " 'test/img_23371.jpg',\n",
       " 'test/img_2014.jpg',\n",
       " 'test/img_51473.jpg',\n",
       " 'test/img_22922.jpg',\n",
       " 'test/img_97513.jpg',\n",
       " 'test/img_69038.jpg',\n",
       " 'test/img_38341.jpg',\n",
       " 'test/img_68553.jpg',\n",
       " 'test/img_92417.jpg',\n",
       " 'test/img_31386.jpg',\n",
       " 'test/img_1986.jpg',\n",
       " 'test/img_15375.jpg',\n",
       " 'test/img_46853.jpg',\n",
       " 'test/img_32013.jpg',\n",
       " 'test/img_30095.jpg',\n",
       " 'test/img_37230.jpg',\n",
       " 'test/img_71024.jpg',\n",
       " 'test/img_30828.jpg',\n",
       " 'test/img_20009.jpg',\n",
       " 'test/img_69453.jpg',\n",
       " 'test/img_6361.jpg',\n",
       " 'test/img_28916.jpg',\n",
       " 'test/img_48179.jpg',\n",
       " 'test/img_87653.jpg',\n",
       " 'test/img_60186.jpg',\n",
       " 'test/img_38409.jpg',\n",
       " 'test/img_41369.jpg',\n",
       " 'test/img_44593.jpg',\n",
       " 'test/img_24216.jpg',\n",
       " 'test/img_61183.jpg',\n",
       " 'test/img_62400.jpg',\n",
       " 'test/img_65961.jpg',\n",
       " 'test/img_65117.jpg',\n",
       " 'test/img_80810.jpg',\n",
       " 'test/img_94610.jpg',\n",
       " 'test/img_32626.jpg',\n",
       " 'test/img_99482.jpg',\n",
       " 'test/img_86993.jpg',\n",
       " 'test/img_98646.jpg',\n",
       " 'test/img_56379.jpg',\n",
       " 'test/img_82578.jpg',\n",
       " 'test/img_46796.jpg',\n",
       " 'test/img_45145.jpg',\n",
       " 'test/img_6308.jpg',\n",
       " 'test/img_52609.jpg',\n",
       " 'test/img_94169.jpg',\n",
       " 'test/img_70822.jpg',\n",
       " 'test/img_16513.jpg',\n",
       " 'test/img_9528.jpg',\n",
       " 'test/img_69549.jpg',\n",
       " 'test/img_9060.jpg',\n",
       " 'test/img_80412.jpg',\n",
       " 'test/img_47049.jpg',\n",
       " 'test/img_78953.jpg',\n",
       " 'test/img_36308.jpg',\n",
       " 'test/img_42229.jpg',\n",
       " 'test/img_57686.jpg',\n",
       " 'test/img_72258.jpg',\n",
       " 'test/img_44620.jpg',\n",
       " 'test/img_62706.jpg',\n",
       " 'test/img_36048.jpg',\n",
       " 'test/img_53489.jpg',\n",
       " 'test/img_74690.jpg',\n",
       " 'test/img_2627.jpg',\n",
       " 'test/img_2478.jpg',\n",
       " 'test/img_7518.jpg',\n",
       " 'test/img_38623.jpg',\n",
       " 'test/img_53379.jpg',\n",
       " 'test/img_98322.jpg',\n",
       " 'test/img_95699.jpg',\n",
       " 'test/img_49482.jpg',\n",
       " 'test/img_92965.jpg',\n",
       " 'test/img_60687.jpg',\n",
       " 'test/img_53101.jpg',\n",
       " 'test/img_68538.jpg',\n",
       " 'test/img_47935.jpg',\n",
       " 'test/img_21262.jpg',\n",
       " 'test/img_73462.jpg',\n",
       " 'test/img_54473.jpg',\n",
       " 'test/img_27189.jpg',\n",
       " 'test/img_60445.jpg',\n",
       " 'test/img_33974.jpg',\n",
       " 'test/img_19222.jpg',\n",
       " 'test/img_13574.jpg',\n",
       " 'test/img_61466.jpg',\n",
       " 'test/img_43714.jpg',\n",
       " 'test/img_22109.jpg',\n",
       " 'test/img_35394.jpg',\n",
       " 'test/img_27303.jpg',\n",
       " 'test/img_825.jpg',\n",
       " 'test/img_100985.jpg',\n",
       " 'test/img_58667.jpg',\n",
       " 'test/img_75730.jpg',\n",
       " 'test/img_93433.jpg',\n",
       " 'test/img_24183.jpg',\n",
       " 'test/img_2062.jpg',\n",
       " 'test/img_61618.jpg',\n",
       " 'test/img_3569.jpg',\n",
       " 'test/img_73040.jpg',\n",
       " 'test/img_20434.jpg',\n",
       " 'test/img_5922.jpg',\n",
       " 'test/img_79344.jpg',\n",
       " 'test/img_71976.jpg',\n",
       " 'test/img_12272.jpg',\n",
       " 'test/img_48609.jpg',\n",
       " 'test/img_20630.jpg',\n",
       " 'test/img_84892.jpg',\n",
       " 'test/img_5427.jpg',\n",
       " 'test/img_12300.jpg',\n",
       " 'test/img_25553.jpg',\n",
       " 'test/img_78982.jpg',\n",
       " 'test/img_75313.jpg',\n",
       " 'test/img_49725.jpg',\n",
       " 'test/img_96138.jpg',\n",
       " 'test/img_74572.jpg',\n",
       " 'test/img_86115.jpg',\n",
       " 'test/img_4208.jpg',\n",
       " 'test/img_26510.jpg',\n",
       " 'test/img_76897.jpg',\n",
       " 'test/img_81893.jpg',\n",
       " 'test/img_58345.jpg',\n",
       " 'test/img_86201.jpg',\n",
       " 'test/img_82285.jpg',\n",
       " 'test/img_5382.jpg',\n",
       " 'test/img_70598.jpg',\n",
       " 'test/img_68861.jpg',\n",
       " 'test/img_29531.jpg',\n",
       " 'test/img_54248.jpg',\n",
       " 'test/img_61340.jpg',\n",
       " 'test/img_39539.jpg',\n",
       " 'test/img_6130.jpg',\n",
       " 'test/img_72926.jpg',\n",
       " 'test/img_52694.jpg',\n",
       " 'test/img_69246.jpg',\n",
       " 'test/img_84230.jpg',\n",
       " 'test/img_2257.jpg',\n",
       " 'test/img_61137.jpg',\n",
       " 'test/img_56339.jpg',\n",
       " 'test/img_14183.jpg',\n",
       " 'test/img_81958.jpg',\n",
       " 'test/img_88162.jpg',\n",
       " 'test/img_23806.jpg',\n",
       " 'test/img_588.jpg',\n",
       " 'test/img_8866.jpg',\n",
       " 'test/img_42916.jpg',\n",
       " 'test/img_31262.jpg',\n",
       " 'test/img_6611.jpg',\n",
       " 'test/img_83324.jpg',\n",
       " 'test/img_79887.jpg',\n",
       " 'test/img_22529.jpg',\n",
       " 'test/img_90560.jpg',\n",
       " 'test/img_71714.jpg',\n",
       " 'test/img_11471.jpg',\n",
       " 'test/img_47917.jpg',\n",
       " 'test/img_50307.jpg',\n",
       " 'test/img_34144.jpg',\n",
       " 'test/img_19853.jpg',\n",
       " 'test/img_30868.jpg',\n",
       " 'test/img_52985.jpg',\n",
       " 'test/img_22560.jpg',\n",
       " 'test/img_81587.jpg',\n",
       " 'test/img_59180.jpg',\n",
       " 'test/img_79167.jpg',\n",
       " 'test/img_10160.jpg',\n",
       " 'test/img_13106.jpg',\n",
       " 'test/img_10951.jpg',\n",
       " 'test/img_92180.jpg',\n",
       " 'test/img_5599.jpg',\n",
       " 'test/img_10311.jpg',\n",
       " 'test/img_85612.jpg',\n",
       " 'test/img_79725.jpg',\n",
       " 'test/img_62200.jpg',\n",
       " 'test/img_1626.jpg',\n",
       " 'test/img_54740.jpg',\n",
       " 'test/img_80602.jpg',\n",
       " 'test/img_46963.jpg',\n",
       " 'test/img_89895.jpg',\n",
       " 'test/img_55391.jpg',\n",
       " 'test/img_29038.jpg',\n",
       " 'test/img_71224.jpg',\n",
       " 'test/img_74390.jpg',\n",
       " 'test/img_92424.jpg',\n",
       " 'test/img_8257.jpg',\n",
       " 'test/img_55139.jpg',\n",
       " 'test/img_23197.jpg',\n",
       " 'test/img_24279.jpg',\n",
       " 'test/img_58203.jpg',\n",
       " 'test/img_85759.jpg',\n",
       " 'test/img_24913.jpg',\n",
       " 'test/img_62887.jpg',\n",
       " 'test/img_22183.jpg',\n",
       " 'test/img_61034.jpg',\n",
       " 'test/img_31841.jpg',\n",
       " 'test/img_90721.jpg',\n",
       " 'test/img_50247.jpg',\n",
       " 'test/img_61522.jpg',\n",
       " 'test/img_75926.jpg',\n",
       " 'test/img_80535.jpg',\n",
       " 'test/img_96982.jpg',\n",
       " 'test/img_81886.jpg',\n",
       " 'test/img_56157.jpg',\n",
       " 'test/img_9652.jpg',\n",
       " 'test/img_36677.jpg',\n",
       " 'test/img_77520.jpg',\n",
       " 'test/img_16393.jpg',\n",
       " 'test/img_89615.jpg',\n",
       " 'test/img_2983.jpg',\n",
       " 'test/img_99356.jpg',\n",
       " 'test/img_15448.jpg',\n",
       " 'test/img_52588.jpg',\n",
       " 'test/img_88978.jpg',\n",
       " 'test/img_73788.jpg',\n",
       " 'test/img_15774.jpg',\n",
       " 'test/img_96017.jpg',\n",
       " 'test/img_81721.jpg',\n",
       " 'test/img_84582.jpg',\n",
       " 'test/img_58692.jpg',\n",
       " 'test/img_101353.jpg',\n",
       " 'test/img_73644.jpg',\n",
       " 'test/img_75789.jpg',\n",
       " 'test/img_55681.jpg',\n",
       " 'test/img_25848.jpg',\n",
       " 'test/img_76087.jpg',\n",
       " 'test/img_65126.jpg',\n",
       " 'test/img_54951.jpg',\n",
       " 'test/img_74175.jpg',\n",
       " 'test/img_82695.jpg',\n",
       " 'test/img_83481.jpg',\n",
       " 'test/img_93080.jpg',\n",
       " 'test/img_30012.jpg',\n",
       " 'test/img_76481.jpg',\n",
       " 'test/img_53969.jpg',\n",
       " 'test/img_13905.jpg',\n",
       " 'test/img_3609.jpg',\n",
       " 'test/img_82553.jpg',\n",
       " 'test/img_88562.jpg',\n",
       " 'test/img_76328.jpg',\n",
       " 'test/img_50787.jpg',\n",
       " 'test/img_19372.jpg',\n",
       " 'test/img_102010.jpg',\n",
       " 'test/img_27981.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_names_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18481, 512, 14, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "#conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3943, 512, 14, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_val_feat=load_array(path+'results/conv_val_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-168e17bb7596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_test_feat\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results/conv_test_feat.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_test_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/utils.py\u001b[0m in \u001b[0;36mload_array\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__getitem__ (bcolz/carray_ext.c:27723)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#conv_test_feat= load_array(path+'results/conv_test_feat.dat')\n",
    "conv_test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Batchnorm dense layers on pretrained conv layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've pre-computed the output of the last convolutional layer, we need to create a network that takes that as input, and predicts our 10 classes. Let's try using a simplified version of VGG's dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18481 samples, validate on 3943 samples\n",
      "Epoch 1/1\n",
      "18481/18481 [==============================] - 7s - loss: 1.5968 - acc: 0.5595 - val_loss: 0.7242 - val_acc: 0.7545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe687c787f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18946 samples, validate on 3478 samples\n",
      "Epoch 1/2\n",
      "18946/18946 [==============================] - 3s - loss: 0.2870 - acc: 0.9109 - val_loss: 0.7728 - val_acc: 0.7683\n",
      "Epoch 2/2\n",
      "18946/18946 [==============================] - 3s - loss: 0.1422 - acc: 0.9594 - val_loss: 0.7576 - val_acc: 0.7936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd921a8d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'conv8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights('/home/ubuntu/data/conv8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking good! Let's try pre-computing 5 epochs worth of augmented data, so we can experiment with combining dropout and augmentation on the pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pre-computed data augmentation + dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use our usual data augmentation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18946 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use those to create a dataset of convolutional features 5x bigger than the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_sample*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_conv_feat2.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(path+'results/da_conv_feat2.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's include the real training data as well in its non-augmented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've now got a dataset 6x bigger than before, we'll need to copy our labels 6 times too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on some experiments the previous model works well, with bigger dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can train the model as usual, with pre-computed augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113676 samples, validate on 3478 samples\n",
      "Epoch 1/1\n",
      "113676/113676 [==============================] - 16s - loss: 1.5848 - acc: 0.5068 - val_loss: 0.6340 - val_acc: 0.8131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd886a7c90>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113676 samples, validate on 3478 samples\n",
      "Epoch 1/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.6652 - acc: 0.7785 - val_loss: 0.6343 - val_acc: 0.8082\n",
      "Epoch 2/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.5247 - acc: 0.8318 - val_loss: 0.6951 - val_acc: 0.8085\n",
      "Epoch 3/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.4553 - acc: 0.8544 - val_loss: 0.6067 - val_acc: 0.8189\n",
      "Epoch 4/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.4127 - acc: 0.8686 - val_loss: 0.7701 - val_acc: 0.7915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd88642490>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113676 samples, validate on 3478 samples\n",
      "Epoch 1/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.3837 - acc: 0.8775 - val_loss: 0.6904 - val_acc: 0.8197\n",
      "Epoch 2/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.3576 - acc: 0.8872 - val_loss: 0.6593 - val_acc: 0.8209\n",
      "Epoch 3/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.3384 - acc: 0.8939 - val_loss: 0.7057 - val_acc: 0.8085\n",
      "Epoch 4/4\n",
      "113676/113676 [==============================] - 16s - loss: 0.3254 - acc: 0.8977 - val_loss: 0.6867 - val_acc: 0.8128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd88642710>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks good - let's save those weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pseudo labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to try using a combination of [pseudo labeling](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf) and [knowledge distillation](https://arxiv.org/abs/1503.02531) to allow us to use unlabeled data (i.e. do semi-supervised learning). For our initial experiment we'll use the validation set as the unlabeled data, so that we can see that it is working without using the test set. At a later date we'll try using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To do this, we simply calculate the predictions of our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_pseudo = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...concatenate them with our training labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([da_trn_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and fine-tune our model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117154 samples, validate on 3478 samples\n",
      "Epoch 1/1\n",
      "117154/117154 [==============================] - 17s - loss: 0.3412 - acc: 0.8948 - val_loss: 0.7653 - val_acc: 0.8191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd88642f50>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117154 samples, validate on 3478 samples\n",
      "Epoch 1/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.3237 - acc: 0.9008 - val_loss: 0.7536 - val_acc: 0.8229\n",
      "Epoch 2/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.3076 - acc: 0.9050 - val_loss: 0.7572 - val_acc: 0.8235\n",
      "Epoch 3/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2984 - acc: 0.9085 - val_loss: 0.7852 - val_acc: 0.8269\n",
      "Epoch 4/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2902 - acc: 0.9117 - val_loss: 0.7630 - val_acc: 0.8263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd89bdd210>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117154 samples, validate on 3478 samples\n",
      "Epoch 1/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2837 - acc: 0.9134 - val_loss: 0.7901 - val_acc: 0.8200\n",
      "Epoch 2/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2760 - acc: 0.9155 - val_loss: 0.7648 - val_acc: 0.8275\n",
      "Epoch 3/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2723 - acc: 0.9183 - val_loss: 0.7382 - val_acc: 0.8358\n",
      "Epoch 4/4\n",
      "117154/117154 [==============================] - 17s - loss: 0.2657 - acc: 0.9191 - val_loss: 0.7227 - val_acc: 0.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd89bb2890>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That's a distinct improvement - even although the validation set isn't very big. This looks encouraging for when we try this on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/bn-ps8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###My Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_test_predict = do_clip(predictTest, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_test_predict[70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(val_batches.class_indices, key=val_batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(clip_test_predict, columns=classes)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.insert(0, 'img', [a[5:] for a in test_file_names])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll find a good clipping amount using the validation set, prior to submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c49c79881ea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.93\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_preds' is not defined"
     ]
    }
   ],
   "source": [
    "keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.93)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045436</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.009486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.028112</td>\n",
       "      <td>0.049419</td>\n",
       "      <td>0.019768</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.254303</td>\n",
       "      <td>0.250345</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.344940</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070440</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.540878</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>0.025106</td>\n",
       "      <td>0.239370</td>\n",
       "      <td>0.053970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c0        c1        c2        c3        c4        c5        c6  \\\n",
       "0  0.007778  0.007778  0.007778  0.045436  0.930000  0.007778  0.007778   \n",
       "1  0.016878  0.009737  0.007778  0.007778  0.007778  0.894503  0.007778   \n",
       "2  0.008118  0.028112  0.049419  0.019768  0.024019  0.254303  0.250345   \n",
       "3  0.070440  0.012862  0.540878  0.007778  0.009317  0.014770  0.028414   \n",
       "4  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000  0.007778   \n",
       "\n",
       "         c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  \n",
       "1  0.028821  0.023224  0.009486  \n",
       "2  0.015021  0.344940  0.007778  \n",
       "3  0.025106  0.239370  0.053970  \n",
       "4  0.007778  0.007778  0.007778  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "#submission.insert(0, 'img', [a[4:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.insert(0, 'img', [a[5:] for a in test_file_names_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_33247.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.045436</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_5097.jpg</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.009486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_78067.jpg</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.028112</td>\n",
       "      <td>0.049419</td>\n",
       "      <td>0.019768</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.254303</td>\n",
       "      <td>0.250345</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.344940</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_70914.jpg</td>\n",
       "      <td>0.070440</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.540878</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>0.025106</td>\n",
       "      <td>0.239370</td>\n",
       "      <td>0.053970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_55371.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_33247.jpg  0.007778  0.007778  0.007778  0.045436  0.930000  0.007778   \n",
       "1   img_5097.jpg  0.016878  0.009737  0.007778  0.007778  0.007778  0.894503   \n",
       "2  img_78067.jpg  0.008118  0.028112  0.049419  0.019768  0.024019  0.254303   \n",
       "3  img_70914.jpg  0.070440  0.012862  0.540878  0.007778  0.009317  0.014770   \n",
       "4  img_55371.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.028821  0.023224  0.009486  \n",
       "2  0.250345  0.015021  0.344940  0.007778  \n",
       "3  0.028414  0.025106  0.239370  0.053970  \n",
       "4  0.007778  0.007778  0.007778  0.007778  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/results/subm.gz' target='_blank'>data/results/subm.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/data/results/subm.gz"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets 0.534 on the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The \"things that didn't really work\" section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can safely ignore everything from here on, because they didn't really help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Finetune some conv layers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in get_bn_layers(p): conv_model.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, conv_model.layers[last_conv_idx+1:]):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in conv_model.layers: l.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in conv_model.layers[last_conv_idx+1:]: l.trainable =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comb = np.concatenate([trn, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=8, height_shift_range=0.04, \n",
    "                shear_range=0.03, channel_shift_range=10, width_shift_range=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "X (images tensor) and y (labels) should have the same length. Found: X.shape = (22424, 3, 224, 224), y.shape = (98208, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8e21fbf7f6e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb_pseudo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, X, y, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m             save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     def flow_from_directory(self, directory,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, X, y, image_data_generator, batch_size, shuffle, seed, dim_ordering, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[0;32m    473\u001b[0m             raise Exception('X (images tensor) and y (labels) '\n\u001b[0;32m    474\u001b[0m                             \u001b[1;34m'should have the same length. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                             'Found: X.shape = %s, y.shape = %s' % (np.asarray(X).shape, np.asarray(y).shape))\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdim_ordering\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdim_ordering\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: X (images tensor) and y (labels) should have the same length. Found: X.shape = (22424, 3, 224, 224), y.shape = (98208, 10)"
     ]
    }
   ],
   "source": [
    "batches = gen_t.flow(comb, comb_pseudo, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3478 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "22400/22424 [============================>.] - ETA: 0s - loss: 0.4348 - acc: 0.9200"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 1644167168 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{(((i0 - i1) // i2) + i2)}}[(0, 1)].0, Elemwise{Composite{(((i0 - i1) // i2) + i2)}}[(0, 1)].0)\nToposort index: 157\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(128), array(64), array(224), array(224)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-50c2f05dc6a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m conv_model.fit_generator(batches, batches.N, nb_epoch=1, validation_data=val_batches, \n\u001b[1;32m----> 2\u001b[1;33m                  nb_val_samples=val_batches.N)\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[0;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                         val_outs = self.evaluate_generator(validation_data,\n\u001b[0;32m   1470\u001b[0m                                                            \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m                                                            max_q_size=max_q_size)\n\u001b[0m\u001b[0;32m   1472\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m                         \u001b[1;31m# no need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1552\u001b[0m                                 'or (x, y). Found: ' + str(generator_output))\n\u001b[0;32m   1553\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1554\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1555\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m                 \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 1644167168 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{(((i0 - i1) // i2) + i2)}}[(0, 1)].0, Elemwise{Composite{(((i0 - i1) // i2) + i2)}}[(0, 1)].0)\nToposort index: 157\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(128), array(64), array(224), array(224)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, batches.N, nb_epoch=1, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_model.fit_generator(batches, batches.N, nb_epoch=3, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in conv_model.layers[16:]: l.trainable =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.optimizer.lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_model.fit_generator(batches, batches.N, nb_epoch=8, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(path+'models/conv8_ps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.load_weights(path+'models/conv8_da.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_pseudo = conv_model.predict(val, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'models/pseudo8_da.dat', val_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_ds = pd.read_csv(path+'driver_imgs_list.csv')\n",
    "drivers_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img2driver = drivers_ds.set_index('img')['subject'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "driver2imgs = {k: g[\"img\"].tolist() \n",
    "               for k,g in drivers_ds[['subject', 'img']].groupby(\"subject\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_idx(driver_list):\n",
    "    return [i for i,f in enumerate(filenames) if img2driver[f[3:]] in driver_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drivers = driver2imgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_drivers = np.random.permutation(drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds1 = rnd_drivers[:len(rnd_drivers)//2]\n",
    "ds2 = rnd_drivers[len(rnd_drivers)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models=[fit_conv([d]) for d in drivers]\n",
    "models=[m for m in models if m is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(conv_test_feat, batch_size=128) for m in models])\n",
    "avg_preds = all_preds.mean(axis=0)\n",
    "avg_preds = avg_preds/np.expand_dims(avg_preds.sum(axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9753041572894531)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_crossentropy(val_labels, np.clip(avg_val_preds,0.01,0.99)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.6949396133422852, dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(val_labels, np.clip(avg_val_preds,0.01,0.99)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
